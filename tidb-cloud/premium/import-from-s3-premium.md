---
title: Import data from Amazon S3 into TiDB Cloud Premium
summary: Learn how to import CSV files from Amazon S3 into TiDB Cloud Premium instances using the console wizard.
---

> **Warning:**
>
> TiDB Cloud Premium is currently available in **Private Preview** in select AWS regions.  
>
> If Premium is not yet enabled for your organization, or if you need access in another cloud provider or region, click **Support** in the lower-left corner of the [TiDB Cloud console](https://tidbcloud.com/), or submit a request through the [Contact Us form](https://www.pingcap.com/contact-us) on our website.

# Import data from Amazon S3 into TiDB Cloud Premium

This document describes how to import CSV files from Amazon Simple Storage Service (Amazon S3) into TiDB Cloud Premium instances. The steps mirror the current Private Preview user interface and are intended as an initial scaffold for the public preview launch.

> **Note:**
>
> For TiDB Cloud Serverless or Essential, see [Import CSV files from cloud storage into TiDB Cloud](/tidb-cloud/import-csv-files-serverless.md). For TiDB Cloud Dedicated, see [Import CSV files from cloud storage into TiDB Cloud Dedicated](/tidb-cloud/import-csv-files.md).

## Limitations

- To ensure data consistency, TiDB Cloud Premium allows importing CSV files into empty tables only. If the target table already contains data, import into a staging table and then copy the rows with `INSERT ... SELECT`.
- During the preview, the UI only surfaces Amazon S3 as the storage provider. Support for additional providers will be tracked separately.
- Each import job maps one source pattern to a single destination table.

## Step 1. Prepare the CSV files

1. If a CSV file is larger than 256 MB, consider splitting it into smaller files around 256 MB so TiDB Cloud Premium can process them in parallel.
2. Name the CSV files following Dumpling conventions:
   - Full-table files use the `${db_name}.${table_name}.csv` format.
   - Sharded files append numeric suffixes, such as `${db_name}.${table_name}.000001.csv`.
   - Compressed files use `${db_name}.${table_name}.${suffix}.csv.${compress}`.
3. Optional schema files (`${db_name}-schema-create.sql`, `${db_name}.${table_name}-schema.sql`) help TiDB Cloud Premium create databases and tables automatically.

<Todo>
These naming conventions are identical to the TiDB Cloud Serverless workflow. Update this section after we validate the Premium defaults.
</Todo>

## Step 2. Create target schemas (optional)

If you want TiDB Cloud Premium to create the databases and tables for you, place the schema files generated by Dumpling in the same S3 directory. Otherwise, create the objects manually in TiDB Cloud Premium before running the import.

## Step 3. Configure Amazon S3 access

To allow TiDB Cloud Premium to read your bucket:

- Provide an AWS Role ARN that trusts TiDB Cloud and grants `s3:GetObject` and `s3:ListBucket` on the relevant paths, or
- Provide an AWS access key (access key ID and secret access key) with equivalent permissions.

The wizard includes a helper link labeled **Click here to create a new one with AWS CloudFormation**. Follow that link if you need TiDB Cloud Premium to pre-fill a CloudFormation stack that creates the role for you.

## Step 4. Import CSV files from Amazon S3

1. Open the Premium workspace in the TiDB Cloud console and select your instance.
2. Go to **Data > Import** and click **Import data from Cloud Storage**.
3. On the **Source Connection** tab:
   - Set **Storage Provider** to **Amazon S3**.
   - Enter the **Source Files URI** for a single file (`s3://bucket/path/file.csv`) or for a folder (`s3://bucket/path/`).
   - Choose **AWS Role ARN** or **AWS Access Key** and provide the credentials.
   - Click **Test Bucket Access** to validate connectivity.
     <Todo>Known preview issue: the button returns to the idle state without a success toast.</Todo>
4. Click **Next** and supply the TiDB SQL username and password for the import job. Optionally test the connection.
5. Review the automatically generated source-to-target mapping. Disable automatic mapping if you need to define custom patterns and destination tables.
6. Click **Next** to run the pre-check. Resolve any warnings about missing files or incompatible schemas.
7. Click **Start Import** to launch the job group.
8. Monitor the job statuses until they show **Completed**, then verify the imported data in TiDB Cloud.

## Troubleshooting

- If the pre-check finds zero files, confirm the S3 path and IAM permissions.
- If jobs remain in **Preparing**, make sure the destination tables are empty and the required schema files exist.
- Use the **Cancel** action to stop a job group if you need to adjust mappings or credentials.

## Next steps

- [Import data into TiDB Cloud Premium via MySQL CLI](/tidb-cloud/premium/import-from-mysql-premium.md) for scripted imports.
- [Troubleshoot import access denied errors](/tidb-cloud/troubleshoot-import-access-denied-error.md) for IAM-related problems.
